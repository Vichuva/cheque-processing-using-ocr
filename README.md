# üè¶ ChequeEasy: OCR-Free Cheque Processing with AI

<div align="center">

![Python](https://img.shields.io/badge/Python-3.7%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Lightning-red)
![Transformers](https://img.shields.io/badge/ü§ó-Transformers-yellow)
![ZenML](https://img.shields.io/badge/ZenML-MLOps-green)
![License](https://img.shields.io/badge/License-MIT-purple)

**An end-to-end MLOps solution for automated cheque processing using Donut Transformer**

[Demo](https://huggingface.co/spaces/shivi/ChequeEasy) ‚Ä¢ [Dataset](https://huggingface.co/datasets/shivi/cheques_sample_data) ‚Ä¢ [Blog Post](https://medium.com/@shivalikasingh95/chequeeasy-banking-with-transformers-f49fb05960d3)

</div>

---

## üìã Overview

**ChequeEasy** is an intelligent cheque processing system that automates the extraction and validation of information from bank cheques. Built with state-of-the-art AI and MLOps best practices, it streamlines the cheque approval process for both bank officials and customers.

### üéØ Key Highlights

- **OCR-Free Processing**: Uses Donut (Document Understanding Transformer) - no traditional OCR required
- **End-to-End MLOps**: Complete pipeline from data annotation to model deployment using ZenML
- **Automated Validation**: Checks for amount matching and stale cheque detection
- **Production Ready**: Includes experiment tracking, model registry, and deployment workflows

---

## ‚ú® Features

### üîç Information Extraction
- **Payee Name**: Automatically extracts the recipient's name
- **Amount in Words**: Captures the legal amount written in text
- **Amount in Figures**: Extracts the courtesy amount (numeric)
- **Cheque Date**: Identifies the date on the cheque
- **Bank Name**: Recognizes the issuing bank

### ‚úÖ Smart Validation
- **Amount Matching**: Verifies that legal and courtesy amounts match
- **Stale Cheque Detection**: Identifies cheques older than 3 months
- **Format Validation**: Ensures data integrity

### üöÄ MLOps Pipeline
- **Data Annotation**: Integrated Label Studio workflow
- **Model Training**: Automated fine-tuning with PyTorch Lightning
- **Experiment Tracking**: MLflow integration for versioning
- **Model Deployment**: Automated deployment based on performance metrics
- **Inference Pipeline**: Production-ready prediction service

---

## üõ†Ô∏è Technology Stack

| Component | Technology |
|-----------|-----------|
| **Model** | [Donut Transformer](https://arxiv.org/abs/2111.15664) (OCR-free VDU) |
| **MLOps Framework** | [ZenML](https://zenml.io/) |
| **Training** | PyTorch Lightning |
| **Experiment Tracking** | MLflow |
| **Data Annotation** | Label Studio |
| **Model Hub** | Hugging Face Transformers & Datasets |
| **Demo Interface** | Gradio |
| **Cloud Storage** | Azure Blob Storage (configurable) |

---

## üìÅ Project Structure

```
cheque-easy-main/
‚îú‚îÄ‚îÄ app.py                          # Gradio demo application
‚îú‚îÄ‚îÄ predict_cheque_parser.py        # Inference script
‚îú‚îÄ‚îÄ run_label_process_data.py       # Labeling pipeline runner
‚îú‚îÄ‚îÄ run_train_deploy.py             # Training & deployment pipeline runner
‚îú‚îÄ‚îÄ params.py                       # Configuration parameters
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ pipelines/                      # ZenML pipelines
‚îÇ   ‚îî‚îÄ‚îÄ cheque_parser/
‚îÇ       ‚îú‚îÄ‚îÄ labelling.py           # Data annotation pipeline
‚îÇ       ‚îú‚îÄ‚îÄ data_postprocess.py    # Data processing pipeline
‚îÇ       ‚îú‚îÄ‚îÄ train_deploy.py        # Training & deployment pipeline
‚îÇ       ‚îî‚îÄ‚îÄ inference_pipeline.py  # Inference pipeline
‚îÇ
‚îú‚îÄ‚îÄ steps/                          # ZenML pipeline steps
‚îÇ   ‚îî‚îÄ‚îÄ cheque_parser/
‚îÇ       ‚îú‚îÄ‚îÄ labelling/             # Annotation steps
‚îÇ       ‚îú‚îÄ‚îÄ data_postprocess/      # Data processing steps
‚îÇ       ‚îú‚îÄ‚îÄ train_donut/           # Training steps
‚îÇ       ‚îî‚îÄ‚îÄ inference/             # Inference steps
‚îÇ
‚îú‚îÄ‚îÄ utils/                          # Utility modules
‚îÇ   ‚îú‚îÄ‚îÄ create_pt_dataset.py       # Dataset creation utilities
‚îÇ   ‚îú‚îÄ‚îÄ donut_pl_module.py         # PyTorch Lightning module
‚îÇ   ‚îî‚îÄ‚îÄ donut_utils.py             # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ materializers/                  # Custom ZenML materializers
‚îÇ   ‚îú‚îÄ‚îÄ config_materializer.py     # Config serialization
‚îÇ   ‚îî‚îÄ‚îÄ donut_processor_materializer.py  # Processor serialization
‚îÇ
‚îî‚îÄ‚îÄ zenml_stacks/                   # ZenML stack configurations
    ‚îú‚îÄ‚îÄ label_data_process_stack.sh
    ‚îî‚îÄ‚îÄ train_inference_stack.sh
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.7, 3.8, or 3.9
- CUDA-capable GPU (recommended for training)
- Azure account (optional, for cloud artifact storage)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Vichuva/cheque-processing-using-ocr.git
   cd cheque-processing-using-ocr
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install ZenML (custom fork with Label Studio OCR support)**
   ```bash
   pip install git+https://github.com/shivalikasingh95/zenml.git@label_studio_ocr_config
   pip install "zenml[server]"
   ```

4. **Install Transformers (custom fork with fixes)**
   ```bash
   pip install git+https://github.com/shivalikasingh95/transformers.git@image_utils_fix
   ```

5. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

6. **Install additional dependencies**
   ```bash
   # For demo app
   pip install word2number gradio symspellpy
   
   # For MySQL backend (optional)
   sudo apt-get update
   sudo apt-get install python3-dev default-libmysqlclient-dev build-essential
   ```

7. **Initialize ZenML**
   ```bash
   zenml init
   zenml up
   ```

### Running the Demo

```bash
python app.py
```

This launches a Gradio interface where you can upload cheque images and see the extracted information.

---

## üìä Dataset

The model is trained on a curated subset of the [Kaggle Cheque Images Dataset](https://www.kaggle.com/datasets/medali1992/cheque-images), focusing on 4 major Indian banks:
- Axis Bank
- Canara Bank
- HSBC
- ICICI Bank

**Download the prepared dataset:**
- ü§ó Hugging Face: [shivi/cheques_sample_data](https://huggingface.co/datasets/shivi/cheques_sample_data)

---

## üîß Usage

### 1. Data Processing Pipeline

Converts raw cheque images and labels into Hugging Face dataset format:

```bash
python run_train_deploy.py --pipeline_type=data_process
```

### 2. Training Pipeline

Fine-tunes the Donut model on the prepared dataset:

```bash
python run_train_deploy.py --pipeline_type=train
```

**Features:**
- Automatic experiment tracking with MLflow
- Model evaluation on test set
- Conditional deployment based on accuracy threshold (>80%)

### 3. Inference Pipeline

Runs predictions on new cheque images:

```bash
python run_train_deploy.py --pipeline_type=inference
```

### 4. Labeling Pipeline (Optional)

For custom dataset annotation using Label Studio:

```bash
# Create annotation project
python run_label_process_data.py --pipeline_type=label

# Start annotation
zenml annotator dataset annotate <dataset_name>

# Retrieve labeled data
python run_label_process_data.py --pipeline_type=get_labelled_data
```

---

## ‚öôÔ∏è Configuration

### Environment Variables for Labeling Stack

```bash
export ANNOT_STACK_NAME="annotation_stack"
export AZURE_KEY_VAULT="your-key-vault"
export STORAGE_ACCOUNT="your-storage-account"
export BUCKET_NAME="az://your-bucket"
export STORAGE_ACCOUNT_KEY="your-access-key"
export LABEL_STUDIO_API_KEY="your-label-studio-token"
export LABEL_DATA_STORAGE_BUCKET_NAME="az://label-data-bucket"
```

### Environment Variables for Training Stack

```bash
export TRAIN_STACK_NAME="training_stack"
export MLFLOW_TRACKING_URI="your-mlflow-uri"
export MLFLOW_USERNAME="your-username"
export MLFLOW_PASSWORD="your-password"
```

### Model Parameters

Edit `params.py` to customize:
- Image size: `[960, 720]`
- Batch size: `1`
- Max epochs: `30`
- Learning rate: `3e-5`
- Minimum accuracy for deployment: `0.8`

---

## üéØ Model Architecture

**Donut (Document Understanding Transformer)** is an OCR-free approach to Visual Document Understanding (VDU):

- **Encoder**: Vision Transformer (ViT) processes document images
- **Decoder**: Transformer decoder generates structured text output
- **No OCR Required**: End-to-end trainable without intermediate OCR steps
- **Task-Agnostic**: Can handle classification, extraction, and VQA

**Benefits over OCR-based approaches:**
- ‚úÖ No need for separate OCR + downstream models
- ‚úÖ Understands document structure natively
- ‚úÖ No hand-crafted rules required
- ‚úÖ Better handling of complex layouts

---

## üé® Demo

Try the live demo on Hugging Face Spaces:

üîó **[ChequeEasy Demo](https://huggingface.co/spaces/shivi/ChequeEasy)**

Upload a cheque image and instantly see:
- Extracted information (payee, amounts, date, bank)
- Amount validation status
- Stale cheque warning

---

## üèóÔ∏è ZenML Stack Setup

### Annotation Stack

```bash
bash zenml_stacks/label_data_process_stack.sh
```

**Components:**
- Artifact Store: Azure Blob Storage
- Secrets Manager: Azure Key Vault
- Annotator: Label Studio

### Training & Inference Stack

```bash
bash zenml_stacks/train_inference_stack.sh
```

**Components:**
- Experiment Tracker: MLflow
- Model Deployer: MLflow
- Artifact Store: Local or Cloud

---

## üìà Performance

The model achieves:
- **Accuracy**: >80% on test set (deployment threshold)
- **Inference Speed**: Real-time processing on GPU
- **Supported Banks**: 4 major Indian banks (expandable)

---

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

1. **Extend to more banks**: Add training data for additional banks
2. **Extract more fields**: MICR code, cheque number, account number
3. **Improve accuracy**: Fine-tune hyperparameters or augment data
4. **Add features**: Multi-language support, signature verification

---

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## üôè Acknowledgments

- **Original Dataset**: [Kaggle Cheque Images](https://www.kaggle.com/datasets/medali1992/cheque-images) by medali1992
- **Donut Model**: [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664) by Naver Clova
- **ZenML**: For the amazing MLOps framework
- **Hugging Face**: For Transformers and Datasets libraries

---

## üìö References

- [Donut Paper](https://arxiv.org/abs/2111.15664) - Kim et al., 2021
- [ZenML Documentation](https://docs.zenml.io/)
- [Blog Post](https://medium.com/@shivalikasingh95/chequeeasy-banking-with-transformers-f49fb05960d3) - Detailed project walkthrough

---

## üìß Contact

For questions or feedback, please open an issue on GitHub.

---

<div align="center">

**Built with ‚ù§Ô∏è for ZenML's Month of MLOps Competition**

‚≠ê Star this repo if you find it useful!

</div>
